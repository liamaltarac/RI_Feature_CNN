{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Concatenate , Add, Dot, Activation, Lambda, BatchNormalization, LeakyReLU, Softmax\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.image import flip_up_down, flip_left_right, rot90\n",
    "from tensorflow.linalg import normalize\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys \n",
    "sys.path.append('..')\n",
    "from layers.sorted_filters import SortedConv2D\n",
    "\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "#tf.disable_v2_behavior()\n",
    "\n",
    "#print(device_lib.list_local_devices())\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "print(tf.__version__ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " sorted_conv2d (SortedConv2D  (None, 32, 32, 16)       162       \n",
      " )                                                               \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16, 16, 16)       64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 16)        0         \n",
      "                                                                 \n",
      " sorted_conv2d_1 (SortedConv  (None, 16, 16, 32)       1570      \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " sorted_conv2d_2 (SortedConv  (None, 16, 16, 32)       3106      \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 8, 8, 32)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 8, 32)          0         \n",
      "                                                                 \n",
      " sorted_conv2d_3 (SortedConv  (None, 8, 8, 64)         6210      \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 4, 4, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4, 4, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               51300     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 593,740\n",
      "Trainable params: 590,444\n",
      "Non-trainable params: 3,296\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_net = Input((32, 32, 3))\n",
    "\n",
    "y = SortedConv2D(filters=16,activation=LeakyReLU(alpha=0.1), padding='SAME')(input_net)\n",
    "y = layers.MaxPooling2D(pool_size=(2, 2))(y) \n",
    "y = layers.BatchNormalization(axis=-1)(y)\n",
    "y = layers.Dropout(0.5)(y)\n",
    "\n",
    "\n",
    "y = SortedConv2D(filters=32,activation=LeakyReLU(alpha=0.1), padding='SAME')(y)\n",
    "y = SortedConv2D(filters=32,activation=LeakyReLU(alpha=0.1), padding='SAME')(y)\n",
    "y = layers.MaxPooling2D(pool_size=(2, 2))(y) \n",
    "y = layers.BatchNormalization(axis=-1)(y)\n",
    "y = layers.Dropout(0.5)(y)\n",
    "\n",
    "y = SortedConv2D(filters=64, activation=LeakyReLU(alpha=0.1), padding='SAME')(y)\n",
    "#y = SortedConv2D(filters=64, activation=LeakyReLU(alpha=0.1), padding='SAME')(y)\n",
    "#y = SortedConv2D(filters=64, activation=LeakyReLU(alpha=0.1), padding='SAME')(y)\n",
    "y = layers.MaxPooling2D(pool_size=(2, 2))(y)\n",
    "y = layers.BatchNormalization(axis=-1)(y)\n",
    "y = layers.Dropout(0.5)(y)\n",
    "\n",
    "y = layers.Flatten()(y)\n",
    "y = layers.BatchNormalization()(y)\n",
    "y = layers.Dense(512, activation=LeakyReLU(alpha=0.1))(y)\n",
    "y = layers.BatchNormalization(axis=-1)(y)\n",
    "y = layers.Dropout(0.2)(y)\n",
    "output_net  = layers.Dense(100, activation=Softmax())(y)\n",
    "\n",
    "model = Model(inputs = input_net, outputs = output_net)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25521224688>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_classes = 100\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "# Load the data and split it between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
    "\n",
    "\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "#x_train = np.expand_dims(x_train, -1)\n",
    "#x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "plt.imshow(x_train[0,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "200/200 [==============================] - 17s 42ms/step - loss: 4.7622 - accuracy: 0.0547 - top-5-accuracy: 0.1827 - val_loss: 4.2532 - val_accuracy: 0.0640 - val_top-5-accuracy: 0.2033\n",
      "Epoch 2/200\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 4.0201 - accuracy: 0.0942 - top-5-accuracy: 0.2752 - val_loss: 3.9390 - val_accuracy: 0.1059 - val_top-5-accuracy: 0.2985\n",
      "Epoch 3/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 3.8539 - accuracy: 0.1163 - top-5-accuracy: 0.3187 - val_loss: 3.8473 - val_accuracy: 0.1250 - val_top-5-accuracy: 0.3278\n",
      "Epoch 4/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 3.8481 - accuracy: 0.1141 - top-5-accuracy: 0.3210 - val_loss: 3.7417 - val_accuracy: 0.1343 - val_top-5-accuracy: 0.3502\n",
      "Epoch 5/200\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 3.7381 - accuracy: 0.1318 - top-5-accuracy: 0.3476 - val_loss: 3.6321 - val_accuracy: 0.1543 - val_top-5-accuracy: 0.3828\n",
      "Epoch 6/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 3.6360 - accuracy: 0.1482 - top-5-accuracy: 0.3795 - val_loss: 3.5658 - val_accuracy: 0.1674 - val_top-5-accuracy: 0.4038\n",
      "Epoch 7/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 3.6881 - accuracy: 0.1365 - top-5-accuracy: 0.3632 - val_loss: 3.6788 - val_accuracy: 0.1457 - val_top-5-accuracy: 0.3783\n",
      "Epoch 8/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 3.6839 - accuracy: 0.1378 - top-5-accuracy: 0.3646 - val_loss: 3.6435 - val_accuracy: 0.1500 - val_top-5-accuracy: 0.3781\n",
      "Epoch 9/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 3.6059 - accuracy: 0.1495 - top-5-accuracy: 0.3880 - val_loss: 3.4896 - val_accuracy: 0.1819 - val_top-5-accuracy: 0.4177\n",
      "Epoch 10/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 3.5158 - accuracy: 0.1675 - top-5-accuracy: 0.4140 - val_loss: 3.4382 - val_accuracy: 0.1897 - val_top-5-accuracy: 0.4440\n",
      "Epoch 11/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 3.4287 - accuracy: 0.1832 - top-5-accuracy: 0.4368 - val_loss: 3.3878 - val_accuracy: 0.1959 - val_top-5-accuracy: 0.4540\n",
      "Epoch 12/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 3.3633 - accuracy: 0.1945 - top-5-accuracy: 0.4591 - val_loss: 3.3310 - val_accuracy: 0.2100 - val_top-5-accuracy: 0.4728\n",
      "Epoch 13/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 3.3770 - accuracy: 0.1897 - top-5-accuracy: 0.4501 - val_loss: 3.4343 - val_accuracy: 0.1862 - val_top-5-accuracy: 0.4392\n",
      "Epoch 14/200\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 3.4231 - accuracy: 0.1824 - top-5-accuracy: 0.4407 - val_loss: 3.3287 - val_accuracy: 0.2039 - val_top-5-accuracy: 0.4686\n",
      "Epoch 15/200\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 3.3130 - accuracy: 0.2013 - top-5-accuracy: 0.4717 - val_loss: 3.2527 - val_accuracy: 0.2205 - val_top-5-accuracy: 0.4831\n",
      "Epoch 16/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 3.2136 - accuracy: 0.2196 - top-5-accuracy: 0.5005 - val_loss: 3.1389 - val_accuracy: 0.2434 - val_top-5-accuracy: 0.5170\n",
      "Epoch 17/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 3.1293 - accuracy: 0.2349 - top-5-accuracy: 0.5236 - val_loss: 3.0917 - val_accuracy: 0.2482 - val_top-5-accuracy: 0.5305\n",
      "Epoch 18/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 3.0580 - accuracy: 0.2491 - top-5-accuracy: 0.5403 - val_loss: 2.9780 - val_accuracy: 0.2762 - val_top-5-accuracy: 0.5534\n",
      "Epoch 19/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.9905 - accuracy: 0.2600 - top-5-accuracy: 0.5563 - val_loss: 2.9548 - val_accuracy: 0.2779 - val_top-5-accuracy: 0.5628\n",
      "Epoch 20/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2.9373 - accuracy: 0.2725 - top-5-accuracy: 0.5710 - val_loss: 2.8736 - val_accuracy: 0.2903 - val_top-5-accuracy: 0.5882\n",
      "Epoch 21/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2.8937 - accuracy: 0.2782 - top-5-accuracy: 0.5824 - val_loss: 2.7905 - val_accuracy: 0.3115 - val_top-5-accuracy: 0.6056\n",
      "Epoch 22/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2.8434 - accuracy: 0.2901 - top-5-accuracy: 0.5935 - val_loss: 2.8141 - val_accuracy: 0.3022 - val_top-5-accuracy: 0.5987\n",
      "Epoch 23/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2.8143 - accuracy: 0.2953 - top-5-accuracy: 0.6008 - val_loss: 2.7690 - val_accuracy: 0.3115 - val_top-5-accuracy: 0.6069\n",
      "Epoch 24/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.7935 - accuracy: 0.2984 - top-5-accuracy: 0.6034 - val_loss: 2.7570 - val_accuracy: 0.3165 - val_top-5-accuracy: 0.6115\n",
      "Epoch 25/200\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 2.7795 - accuracy: 0.3057 - top-5-accuracy: 0.6064 - val_loss: 2.7559 - val_accuracy: 0.3169 - val_top-5-accuracy: 0.6121\n",
      "Epoch 26/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.8617 - accuracy: 0.2872 - top-5-accuracy: 0.5887 - val_loss: 2.9951 - val_accuracy: 0.2726 - val_top-5-accuracy: 0.5738\n",
      "Epoch 27/200\n",
      "200/200 [==============================] - 6s 31ms/step - loss: 2.9668 - accuracy: 0.2646 - top-5-accuracy: 0.5641 - val_loss: 3.1994 - val_accuracy: 0.2388 - val_top-5-accuracy: 0.5205\n",
      "Epoch 28/200\n",
      "200/200 [==============================] - 6s 31ms/step - loss: 2.9288 - accuracy: 0.2731 - top-5-accuracy: 0.5756 - val_loss: 3.0780 - val_accuracy: 0.2590 - val_top-5-accuracy: 0.5358\n",
      "Epoch 29/200\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 2.9068 - accuracy: 0.2767 - top-5-accuracy: 0.5776 - val_loss: 3.0966 - val_accuracy: 0.2614 - val_top-5-accuracy: 0.5468\n",
      "Epoch 30/200\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 2.8733 - accuracy: 0.2824 - top-5-accuracy: 0.5855 - val_loss: 2.9178 - val_accuracy: 0.2877 - val_top-5-accuracy: 0.5789\n",
      "Epoch 31/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.8437 - accuracy: 0.2868 - top-5-accuracy: 0.5952 - val_loss: 3.0900 - val_accuracy: 0.2643 - val_top-5-accuracy: 0.5443\n",
      "Epoch 32/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.8120 - accuracy: 0.2945 - top-5-accuracy: 0.6017 - val_loss: 2.9194 - val_accuracy: 0.2838 - val_top-5-accuracy: 0.5742\n",
      "Epoch 33/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2.7812 - accuracy: 0.3008 - top-5-accuracy: 0.6077 - val_loss: 2.7534 - val_accuracy: 0.3139 - val_top-5-accuracy: 0.6134\n",
      "Epoch 34/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.7546 - accuracy: 0.3056 - top-5-accuracy: 0.6162 - val_loss: 2.7150 - val_accuracy: 0.3266 - val_top-5-accuracy: 0.6208\n",
      "Epoch 35/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.7261 - accuracy: 0.3105 - top-5-accuracy: 0.6230 - val_loss: 2.8165 - val_accuracy: 0.3149 - val_top-5-accuracy: 0.6068\n",
      "Epoch 36/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.6944 - accuracy: 0.3171 - top-5-accuracy: 0.6274 - val_loss: 3.0235 - val_accuracy: 0.2772 - val_top-5-accuracy: 0.5647\n",
      "Epoch 37/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.6750 - accuracy: 0.3203 - top-5-accuracy: 0.6339 - val_loss: 2.5867 - val_accuracy: 0.3483 - val_top-5-accuracy: 0.6468\n",
      "Epoch 38/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.6439 - accuracy: 0.3288 - top-5-accuracy: 0.6422 - val_loss: 2.6415 - val_accuracy: 0.3391 - val_top-5-accuracy: 0.6372\n",
      "Epoch 39/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.6262 - accuracy: 0.3296 - top-5-accuracy: 0.6458 - val_loss: 2.5480 - val_accuracy: 0.3612 - val_top-5-accuracy: 0.6566\n",
      "Epoch 40/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.5880 - accuracy: 0.3393 - top-5-accuracy: 0.6532 - val_loss: 2.6423 - val_accuracy: 0.3401 - val_top-5-accuracy: 0.6420\n",
      "Epoch 41/200\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 2.5698 - accuracy: 0.3431 - top-5-accuracy: 0.6560 - val_loss: 2.5140 - val_accuracy: 0.3670 - val_top-5-accuracy: 0.6680\n",
      "Epoch 42/200\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 2.5475 - accuracy: 0.3482 - top-5-accuracy: 0.6605 - val_loss: 2.5691 - val_accuracy: 0.3548 - val_top-5-accuracy: 0.6519\n",
      "Epoch 43/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.5315 - accuracy: 0.3508 - top-5-accuracy: 0.6668 - val_loss: 2.5227 - val_accuracy: 0.3655 - val_top-5-accuracy: 0.6601\n",
      "Epoch 44/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.5132 - accuracy: 0.3583 - top-5-accuracy: 0.6684 - val_loss: 2.5421 - val_accuracy: 0.3586 - val_top-5-accuracy: 0.6598\n",
      "Epoch 45/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.4941 - accuracy: 0.3609 - top-5-accuracy: 0.6757 - val_loss: 2.4919 - val_accuracy: 0.3752 - val_top-5-accuracy: 0.6717\n",
      "Epoch 46/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2.4853 - accuracy: 0.3600 - top-5-accuracy: 0.6776 - val_loss: 2.5004 - val_accuracy: 0.3720 - val_top-5-accuracy: 0.6721\n",
      "Epoch 47/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.4688 - accuracy: 0.3639 - top-5-accuracy: 0.6805 - val_loss: 2.5089 - val_accuracy: 0.3684 - val_top-5-accuracy: 0.6671\n",
      "Epoch 48/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.4643 - accuracy: 0.3653 - top-5-accuracy: 0.6809 - val_loss: 2.4837 - val_accuracy: 0.3750 - val_top-5-accuracy: 0.6749\n",
      "Epoch 49/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2.4478 - accuracy: 0.3689 - top-5-accuracy: 0.6860 - val_loss: 2.4809 - val_accuracy: 0.3739 - val_top-5-accuracy: 0.6737\n",
      "Epoch 50/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.4473 - accuracy: 0.3684 - top-5-accuracy: 0.6814 - val_loss: 2.4842 - val_accuracy: 0.3723 - val_top-5-accuracy: 0.6720\n",
      "Epoch 51/200\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 2.4487 - accuracy: 0.3691 - top-5-accuracy: 0.6827 - val_loss: 2.4858 - val_accuracy: 0.3715 - val_top-5-accuracy: 0.6719\n",
      "Epoch 52/200\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 2.6517 - accuracy: 0.3268 - top-5-accuracy: 0.6416 - val_loss: 2.6870 - val_accuracy: 0.3434 - val_top-5-accuracy: 0.6393\n",
      "Epoch 53/200\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 2.6816 - accuracy: 0.3214 - top-5-accuracy: 0.6358 - val_loss: 2.7259 - val_accuracy: 0.3215 - val_top-5-accuracy: 0.6191\n",
      "Epoch 54/200\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 2.6713 - accuracy: 0.3231 - top-5-accuracy: 0.6333 - val_loss: 2.6303 - val_accuracy: 0.3416 - val_top-5-accuracy: 0.6494\n",
      "Epoch 55/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2.6624 - accuracy: 0.3244 - top-5-accuracy: 0.6361 - val_loss: 2.6957 - val_accuracy: 0.3342 - val_top-5-accuracy: 0.6344\n",
      "Epoch 56/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.6476 - accuracy: 0.3271 - top-5-accuracy: 0.6418 - val_loss: 2.5957 - val_accuracy: 0.3538 - val_top-5-accuracy: 0.6565\n",
      "Epoch 57/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2.6320 - accuracy: 0.3324 - top-5-accuracy: 0.6457 - val_loss: 2.6212 - val_accuracy: 0.3492 - val_top-5-accuracy: 0.6487\n",
      "Epoch 58/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2.6275 - accuracy: 0.3321 - top-5-accuracy: 0.6453 - val_loss: 2.7482 - val_accuracy: 0.3258 - val_top-5-accuracy: 0.6258\n",
      "Epoch 59/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2.5934 - accuracy: 0.3376 - top-5-accuracy: 0.6543 - val_loss: 2.7240 - val_accuracy: 0.3377 - val_top-5-accuracy: 0.6256\n",
      "Epoch 60/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.5775 - accuracy: 0.3405 - top-5-accuracy: 0.6575 - val_loss: 2.6935 - val_accuracy: 0.3393 - val_top-5-accuracy: 0.6241\n",
      "Epoch 61/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2.5524 - accuracy: 0.3443 - top-5-accuracy: 0.6622 - val_loss: 2.7285 - val_accuracy: 0.3279 - val_top-5-accuracy: 0.6219\n",
      "Epoch 62/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.5391 - accuracy: 0.3467 - top-5-accuracy: 0.6663 - val_loss: 2.5647 - val_accuracy: 0.3588 - val_top-5-accuracy: 0.6554\n",
      "Epoch 63/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.5222 - accuracy: 0.3519 - top-5-accuracy: 0.6702 - val_loss: 2.6052 - val_accuracy: 0.3611 - val_top-5-accuracy: 0.6584\n",
      "Epoch 64/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.5053 - accuracy: 0.3582 - top-5-accuracy: 0.6725 - val_loss: 2.7687 - val_accuracy: 0.3165 - val_top-5-accuracy: 0.6278\n",
      "Epoch 65/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.4875 - accuracy: 0.3580 - top-5-accuracy: 0.6786 - val_loss: 2.5509 - val_accuracy: 0.3575 - val_top-5-accuracy: 0.6592\n",
      "Epoch 66/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.4732 - accuracy: 0.3607 - top-5-accuracy: 0.6794 - val_loss: 2.4381 - val_accuracy: 0.3764 - val_top-5-accuracy: 0.6824\n",
      "Epoch 67/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.4517 - accuracy: 0.3646 - top-5-accuracy: 0.6854 - val_loss: 3.0338 - val_accuracy: 0.2842 - val_top-5-accuracy: 0.5785\n",
      "Epoch 68/200\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 2.4434 - accuracy: 0.3673 - top-5-accuracy: 0.6883 - val_loss: 2.4491 - val_accuracy: 0.3779 - val_top-5-accuracy: 0.6857\n",
      "Epoch 69/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.4324 - accuracy: 0.3679 - top-5-accuracy: 0.6903 - val_loss: 2.3456 - val_accuracy: 0.3969 - val_top-5-accuracy: 0.7047\n",
      "Epoch 70/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.4140 - accuracy: 0.3745 - top-5-accuracy: 0.6912 - val_loss: 2.4925 - val_accuracy: 0.3761 - val_top-5-accuracy: 0.6700\n",
      "Epoch 71/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.4047 - accuracy: 0.3749 - top-5-accuracy: 0.6950 - val_loss: 2.4490 - val_accuracy: 0.3803 - val_top-5-accuracy: 0.6753\n",
      "Epoch 72/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.3916 - accuracy: 0.3778 - top-5-accuracy: 0.6973 - val_loss: 2.4660 - val_accuracy: 0.3804 - val_top-5-accuracy: 0.6829\n",
      "Epoch 73/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.3820 - accuracy: 0.3802 - top-5-accuracy: 0.6998 - val_loss: 2.4214 - val_accuracy: 0.3866 - val_top-5-accuracy: 0.6878\n",
      "Epoch 74/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.3596 - accuracy: 0.3857 - top-5-accuracy: 0.7051 - val_loss: 2.4810 - val_accuracy: 0.3808 - val_top-5-accuracy: 0.6772\n",
      "Epoch 75/200\n",
      "200/200 [==============================] - 6s 33ms/step - loss: 2.3517 - accuracy: 0.3859 - top-5-accuracy: 0.7074 - val_loss: 2.3440 - val_accuracy: 0.4031 - val_top-5-accuracy: 0.7048\n",
      "Epoch 76/200\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 2.3339 - accuracy: 0.3894 - top-5-accuracy: 0.7091 - val_loss: 2.4380 - val_accuracy: 0.3874 - val_top-5-accuracy: 0.6874\n",
      "Epoch 77/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.3149 - accuracy: 0.3965 - top-5-accuracy: 0.7128 - val_loss: 2.4822 - val_accuracy: 0.3779 - val_top-5-accuracy: 0.6765\n",
      "Epoch 78/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.3086 - accuracy: 0.3959 - top-5-accuracy: 0.7158 - val_loss: 2.3934 - val_accuracy: 0.3953 - val_top-5-accuracy: 0.6948\n",
      "Epoch 79/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.2938 - accuracy: 0.4000 - top-5-accuracy: 0.7189 - val_loss: 2.3914 - val_accuracy: 0.3963 - val_top-5-accuracy: 0.6969\n",
      "Epoch 80/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.2767 - accuracy: 0.4035 - top-5-accuracy: 0.7215 - val_loss: 2.3156 - val_accuracy: 0.4086 - val_top-5-accuracy: 0.7063\n",
      "Epoch 81/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.2654 - accuracy: 0.4030 - top-5-accuracy: 0.7246 - val_loss: 2.6207 - val_accuracy: 0.3526 - val_top-5-accuracy: 0.6534\n",
      "Epoch 82/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.2564 - accuracy: 0.4048 - top-5-accuracy: 0.7271 - val_loss: 2.3153 - val_accuracy: 0.4110 - val_top-5-accuracy: 0.7107\n",
      "Epoch 83/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.2531 - accuracy: 0.4082 - top-5-accuracy: 0.7259 - val_loss: 2.3434 - val_accuracy: 0.4039 - val_top-5-accuracy: 0.7083\n",
      "Epoch 84/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.2371 - accuracy: 0.4091 - top-5-accuracy: 0.7300 - val_loss: 2.2852 - val_accuracy: 0.4185 - val_top-5-accuracy: 0.7154\n",
      "Epoch 85/200\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 2.2259 - accuracy: 0.4153 - top-5-accuracy: 0.7293 - val_loss: 2.3132 - val_accuracy: 0.4101 - val_top-5-accuracy: 0.7150\n",
      "Epoch 86/200\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 2.2147 - accuracy: 0.4161 - top-5-accuracy: 0.7345 - val_loss: 2.2823 - val_accuracy: 0.4176 - val_top-5-accuracy: 0.7176\n",
      "Epoch 87/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2.2158 - accuracy: 0.4167 - top-5-accuracy: 0.7346 - val_loss: 2.3390 - val_accuracy: 0.4102 - val_top-5-accuracy: 0.7061\n",
      "Epoch 88/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2.1966 - accuracy: 0.4199 - top-5-accuracy: 0.7372 - val_loss: 2.3026 - val_accuracy: 0.4169 - val_top-5-accuracy: 0.7153\n",
      "Epoch 89/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.1914 - accuracy: 0.4227 - top-5-accuracy: 0.7380 - val_loss: 2.3180 - val_accuracy: 0.4116 - val_top-5-accuracy: 0.7123\n",
      "Epoch 90/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.1869 - accuracy: 0.4229 - top-5-accuracy: 0.7375 - val_loss: 2.2473 - val_accuracy: 0.4245 - val_top-5-accuracy: 0.7233\n",
      "Epoch 91/200\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 2.1809 - accuracy: 0.4258 - top-5-accuracy: 0.7392 - val_loss: 2.2427 - val_accuracy: 0.4264 - val_top-5-accuracy: 0.7243\n",
      "Epoch 92/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.1725 - accuracy: 0.4238 - top-5-accuracy: 0.7416 - val_loss: 2.2933 - val_accuracy: 0.4200 - val_top-5-accuracy: 0.7171\n",
      "Epoch 93/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2.1666 - accuracy: 0.4269 - top-5-accuracy: 0.7433 - val_loss: 2.3100 - val_accuracy: 0.4157 - val_top-5-accuracy: 0.7145\n",
      "Epoch 94/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.1536 - accuracy: 0.4310 - top-5-accuracy: 0.7458 - val_loss: 2.2337 - val_accuracy: 0.4275 - val_top-5-accuracy: 0.7279\n",
      "Epoch 95/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2.1587 - accuracy: 0.4295 - top-5-accuracy: 0.7455 - val_loss: 2.3181 - val_accuracy: 0.4095 - val_top-5-accuracy: 0.7144\n",
      "Epoch 96/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.1516 - accuracy: 0.4309 - top-5-accuracy: 0.7448 - val_loss: 2.2427 - val_accuracy: 0.4261 - val_top-5-accuracy: 0.7264\n",
      "Epoch 97/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.1526 - accuracy: 0.4335 - top-5-accuracy: 0.7442 - val_loss: 2.2363 - val_accuracy: 0.4266 - val_top-5-accuracy: 0.7271\n",
      "Epoch 98/200\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 2.1416 - accuracy: 0.4312 - top-5-accuracy: 0.7506 - val_loss: 2.2386 - val_accuracy: 0.4272 - val_top-5-accuracy: 0.7267\n",
      "Epoch 99/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2.1338 - accuracy: 0.4365 - top-5-accuracy: 0.7495 - val_loss: 2.2492 - val_accuracy: 0.4259 - val_top-5-accuracy: 0.7247\n",
      "Epoch 100/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.1449 - accuracy: 0.4321 - top-5-accuracy: 0.7489 - val_loss: 2.2471 - val_accuracy: 0.4265 - val_top-5-accuracy: 0.7257\n",
      "Epoch 101/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.1323 - accuracy: 0.4340 - top-5-accuracy: 0.7496 - val_loss: 2.2397 - val_accuracy: 0.4279 - val_top-5-accuracy: 0.7278\n",
      "Epoch 102/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.1427 - accuracy: 0.4315 - top-5-accuracy: 0.7492 - val_loss: 2.2404 - val_accuracy: 0.4274 - val_top-5-accuracy: 0.7274\n",
      "Epoch 103/200\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 2.3060 - accuracy: 0.3977 - top-5-accuracy: 0.7148 - val_loss: 2.3813 - val_accuracy: 0.3972 - val_top-5-accuracy: 0.6928\n",
      "Epoch 104/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.3997 - accuracy: 0.3748 - top-5-accuracy: 0.6980 - val_loss: 2.5985 - val_accuracy: 0.3614 - val_top-5-accuracy: 0.6626\n",
      "Epoch 105/200\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 2.4015 - accuracy: 0.3789 - top-5-accuracy: 0.6969 - val_loss: 2.4700 - val_accuracy: 0.3769 - val_top-5-accuracy: 0.6787\n",
      "Epoch 106/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.4039 - accuracy: 0.3754 - top-5-accuracy: 0.6975 - val_loss: 2.3715 - val_accuracy: 0.3947 - val_top-5-accuracy: 0.7030\n",
      "Epoch 107/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.3977 - accuracy: 0.3773 - top-5-accuracy: 0.6979 - val_loss: 2.5277 - val_accuracy: 0.3695 - val_top-5-accuracy: 0.6674\n",
      "Epoch 108/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.3921 - accuracy: 0.3773 - top-5-accuracy: 0.7004 - val_loss: 2.3989 - val_accuracy: 0.4012 - val_top-5-accuracy: 0.7050\n",
      "Epoch 109/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.3889 - accuracy: 0.3815 - top-5-accuracy: 0.7003 - val_loss: 2.4652 - val_accuracy: 0.3778 - val_top-5-accuracy: 0.6834\n",
      "Epoch 110/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.3885 - accuracy: 0.3783 - top-5-accuracy: 0.6989 - val_loss: 2.5802 - val_accuracy: 0.3601 - val_top-5-accuracy: 0.6614\n",
      "Epoch 111/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.3813 - accuracy: 0.3814 - top-5-accuracy: 0.7033 - val_loss: 2.3372 - val_accuracy: 0.4074 - val_top-5-accuracy: 0.7069\n",
      "Epoch 112/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.3800 - accuracy: 0.3833 - top-5-accuracy: 0.7009 - val_loss: 2.3892 - val_accuracy: 0.3972 - val_top-5-accuracy: 0.7016\n",
      "Epoch 113/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2.3722 - accuracy: 0.3824 - top-5-accuracy: 0.7039 - val_loss: 2.5132 - val_accuracy: 0.3735 - val_top-5-accuracy: 0.6792\n",
      "Epoch 114/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.3702 - accuracy: 0.3830 - top-5-accuracy: 0.7043 - val_loss: 2.4891 - val_accuracy: 0.3732 - val_top-5-accuracy: 0.6746\n",
      "Epoch 115/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2.3544 - accuracy: 0.3861 - top-5-accuracy: 0.7065 - val_loss: 3.0982 - val_accuracy: 0.2856 - val_top-5-accuracy: 0.5741\n",
      "Epoch 116/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.3512 - accuracy: 0.3861 - top-5-accuracy: 0.7097 - val_loss: 2.4684 - val_accuracy: 0.3818 - val_top-5-accuracy: 0.6904\n",
      "Epoch 117/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.3474 - accuracy: 0.3875 - top-5-accuracy: 0.7088 - val_loss: 2.3879 - val_accuracy: 0.4007 - val_top-5-accuracy: 0.7002\n",
      "Epoch 118/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2.3463 - accuracy: 0.3866 - top-5-accuracy: 0.7078 - val_loss: 2.5330 - val_accuracy: 0.3784 - val_top-5-accuracy: 0.6840\n",
      "Epoch 119/200\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 2.3381 - accuracy: 0.3897 - top-5-accuracy: 0.7120 - val_loss: 3.0142 - val_accuracy: 0.3004 - val_top-5-accuracy: 0.5800\n",
      "Epoch 120/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.3353 - accuracy: 0.3897 - top-5-accuracy: 0.7099 - val_loss: 2.5845 - val_accuracy: 0.3701 - val_top-5-accuracy: 0.6619\n",
      "Epoch 121/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.3315 - accuracy: 0.3925 - top-5-accuracy: 0.7125 - val_loss: 2.5081 - val_accuracy: 0.3742 - val_top-5-accuracy: 0.6740\n",
      "Epoch 122/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.3259 - accuracy: 0.3917 - top-5-accuracy: 0.7135 - val_loss: 2.5071 - val_accuracy: 0.3724 - val_top-5-accuracy: 0.6734\n",
      "Epoch 123/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.2995 - accuracy: 0.3955 - top-5-accuracy: 0.7198 - val_loss: 2.4578 - val_accuracy: 0.3809 - val_top-5-accuracy: 0.6949\n",
      "Epoch 124/200\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 2.3133 - accuracy: 0.3955 - top-5-accuracy: 0.7157 - val_loss: 2.5896 - val_accuracy: 0.3682 - val_top-5-accuracy: 0.6806\n",
      "Epoch 125/200\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 2.2978 - accuracy: 0.4006 - top-5-accuracy: 0.7204 - val_loss: 2.3789 - val_accuracy: 0.4011 - val_top-5-accuracy: 0.7036\n",
      "Epoch 126/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.2953 - accuracy: 0.4001 - top-5-accuracy: 0.7200 - val_loss: 2.4951 - val_accuracy: 0.3779 - val_top-5-accuracy: 0.6813\n",
      "Epoch 127/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.2880 - accuracy: 0.4018 - top-5-accuracy: 0.7210 - val_loss: 2.4513 - val_accuracy: 0.3913 - val_top-5-accuracy: 0.6924\n",
      "Epoch 128/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.2870 - accuracy: 0.4002 - top-5-accuracy: 0.7215 - val_loss: 2.8291 - val_accuracy: 0.3192 - val_top-5-accuracy: 0.6210\n",
      "Epoch 129/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.2749 - accuracy: 0.4009 - top-5-accuracy: 0.7216 - val_loss: 2.3838 - val_accuracy: 0.4041 - val_top-5-accuracy: 0.7054\n",
      "Epoch 130/200\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 2.2831 - accuracy: 0.3998 - top-5-accuracy: 0.7208 - val_loss: 2.2956 - val_accuracy: 0.4159 - val_top-5-accuracy: 0.7176\n",
      "Epoch 131/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.2719 - accuracy: 0.4043 - top-5-accuracy: 0.7238 - val_loss: 2.2724 - val_accuracy: 0.4200 - val_top-5-accuracy: 0.7173\n",
      "Epoch 132/200\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 2.2568 - accuracy: 0.4047 - top-5-accuracy: 0.7268 - val_loss: 2.5481 - val_accuracy: 0.3706 - val_top-5-accuracy: 0.6719\n",
      "Epoch 133/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.2523 - accuracy: 0.4043 - top-5-accuracy: 0.7278 - val_loss: 2.4625 - val_accuracy: 0.3862 - val_top-5-accuracy: 0.6858\n",
      "Epoch 134/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.2542 - accuracy: 0.4082 - top-5-accuracy: 0.7280 - val_loss: 2.3886 - val_accuracy: 0.3976 - val_top-5-accuracy: 0.7005\n",
      "Epoch 135/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.2398 - accuracy: 0.4087 - top-5-accuracy: 0.7316 - val_loss: 2.3861 - val_accuracy: 0.3886 - val_top-5-accuracy: 0.6962\n",
      "Epoch 136/200\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 2.2402 - accuracy: 0.4094 - top-5-accuracy: 0.7308 - val_loss: 2.2566 - val_accuracy: 0.4227 - val_top-5-accuracy: 0.7265\n",
      "Epoch 137/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.2371 - accuracy: 0.4116 - top-5-accuracy: 0.7304 - val_loss: 2.3008 - val_accuracy: 0.4125 - val_top-5-accuracy: 0.7112\n",
      "Epoch 138/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.2248 - accuracy: 0.4148 - top-5-accuracy: 0.7334 - val_loss: 2.2717 - val_accuracy: 0.4246 - val_top-5-accuracy: 0.7228\n",
      "Epoch 139/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2.2116 - accuracy: 0.4175 - top-5-accuracy: 0.7367 - val_loss: 2.3295 - val_accuracy: 0.4127 - val_top-5-accuracy: 0.7094\n",
      "Epoch 140/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.2152 - accuracy: 0.4145 - top-5-accuracy: 0.7365 - val_loss: 2.3292 - val_accuracy: 0.4128 - val_top-5-accuracy: 0.7192\n",
      "Epoch 141/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.2059 - accuracy: 0.4164 - top-5-accuracy: 0.7378 - val_loss: 2.3186 - val_accuracy: 0.4092 - val_top-5-accuracy: 0.7106\n",
      "Epoch 142/200\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 2.1958 - accuracy: 0.4207 - top-5-accuracy: 0.7413 - val_loss: 2.3085 - val_accuracy: 0.4163 - val_top-5-accuracy: 0.7116\n",
      "Epoch 143/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2.1959 - accuracy: 0.4177 - top-5-accuracy: 0.7390 - val_loss: 2.2754 - val_accuracy: 0.4214 - val_top-5-accuracy: 0.7197\n",
      "Epoch 144/200\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 2.1897 - accuracy: 0.4207 - top-5-accuracy: 0.7391 - val_loss: 2.2684 - val_accuracy: 0.4185 - val_top-5-accuracy: 0.7248\n",
      "Epoch 145/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.1840 - accuracy: 0.4232 - top-5-accuracy: 0.7408 - val_loss: 2.2805 - val_accuracy: 0.4194 - val_top-5-accuracy: 0.7179\n",
      "Epoch 146/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.1745 - accuracy: 0.4240 - top-5-accuracy: 0.7442 - val_loss: 2.2679 - val_accuracy: 0.4197 - val_top-5-accuracy: 0.7168\n",
      "Epoch 147/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.1666 - accuracy: 0.4248 - top-5-accuracy: 0.7454 - val_loss: 2.2469 - val_accuracy: 0.4290 - val_top-5-accuracy: 0.7319\n",
      "Epoch 148/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.1683 - accuracy: 0.4261 - top-5-accuracy: 0.7446 - val_loss: 2.2073 - val_accuracy: 0.4359 - val_top-5-accuracy: 0.7318\n",
      "Epoch 149/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2.1567 - accuracy: 0.4293 - top-5-accuracy: 0.7478 - val_loss: 2.2063 - val_accuracy: 0.4363 - val_top-5-accuracy: 0.7316\n",
      "Epoch 150/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.1505 - accuracy: 0.4283 - top-5-accuracy: 0.7487 - val_loss: 2.3423 - val_accuracy: 0.4090 - val_top-5-accuracy: 0.7050\n",
      "Epoch 151/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.1429 - accuracy: 0.4302 - top-5-accuracy: 0.7491 - val_loss: 2.3101 - val_accuracy: 0.4144 - val_top-5-accuracy: 0.7175\n",
      "Epoch 152/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.1362 - accuracy: 0.4310 - top-5-accuracy: 0.7504 - val_loss: 2.2875 - val_accuracy: 0.4186 - val_top-5-accuracy: 0.7209\n",
      "Epoch 153/200\n",
      "200/200 [==============================] - 6s 31ms/step - loss: 2.1325 - accuracy: 0.4334 - top-5-accuracy: 0.7505 - val_loss: 2.1967 - val_accuracy: 0.4381 - val_top-5-accuracy: 0.7368\n",
      "Epoch 154/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.1299 - accuracy: 0.4329 - top-5-accuracy: 0.7520 - val_loss: 2.1981 - val_accuracy: 0.4374 - val_top-5-accuracy: 0.7389\n",
      "Epoch 155/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.1167 - accuracy: 0.4361 - top-5-accuracy: 0.7556 - val_loss: 2.2674 - val_accuracy: 0.4288 - val_top-5-accuracy: 0.7241\n",
      "Epoch 156/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.1173 - accuracy: 0.4358 - top-5-accuracy: 0.7537 - val_loss: 2.1970 - val_accuracy: 0.4370 - val_top-5-accuracy: 0.7309\n",
      "Epoch 157/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 2.1155 - accuracy: 0.4363 - top-5-accuracy: 0.7545 - val_loss: 2.2505 - val_accuracy: 0.4245 - val_top-5-accuracy: 0.7172\n",
      "Epoch 158/200\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 2.1031 - accuracy: 0.4388 - top-5-accuracy: 0.7563 - val_loss: 2.3269 - val_accuracy: 0.4132 - val_top-5-accuracy: 0.7074\n",
      "Epoch 159/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.1066 - accuracy: 0.4384 - top-5-accuracy: 0.7566 - val_loss: 2.1795 - val_accuracy: 0.4418 - val_top-5-accuracy: 0.7347\n",
      "Epoch 160/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.0959 - accuracy: 0.4398 - top-5-accuracy: 0.7607 - val_loss: 2.1774 - val_accuracy: 0.4381 - val_top-5-accuracy: 0.7401\n",
      "Epoch 161/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.0842 - accuracy: 0.4415 - top-5-accuracy: 0.7617 - val_loss: 2.1343 - val_accuracy: 0.4486 - val_top-5-accuracy: 0.7483\n",
      "Epoch 162/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.0756 - accuracy: 0.4468 - top-5-accuracy: 0.7610 - val_loss: 2.1570 - val_accuracy: 0.4424 - val_top-5-accuracy: 0.7378\n",
      "Epoch 163/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.0669 - accuracy: 0.4472 - top-5-accuracy: 0.7615 - val_loss: 2.1730 - val_accuracy: 0.4476 - val_top-5-accuracy: 0.7391\n",
      "Epoch 164/200\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 2.0709 - accuracy: 0.4486 - top-5-accuracy: 0.7629 - val_loss: 2.1483 - val_accuracy: 0.4475 - val_top-5-accuracy: 0.7490\n",
      "Epoch 165/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.0749 - accuracy: 0.4466 - top-5-accuracy: 0.7630 - val_loss: 2.2270 - val_accuracy: 0.4312 - val_top-5-accuracy: 0.7316\n",
      "Epoch 166/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.0652 - accuracy: 0.4460 - top-5-accuracy: 0.7640 - val_loss: 2.1769 - val_accuracy: 0.4442 - val_top-5-accuracy: 0.7400\n",
      "Epoch 167/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.0543 - accuracy: 0.4513 - top-5-accuracy: 0.7656 - val_loss: 2.2016 - val_accuracy: 0.4332 - val_top-5-accuracy: 0.7319\n",
      "Epoch 168/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 2.0498 - accuracy: 0.4549 - top-5-accuracy: 0.7668 - val_loss: 2.1414 - val_accuracy: 0.4489 - val_top-5-accuracy: 0.7445\n",
      "Epoch 169/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.0355 - accuracy: 0.4565 - top-5-accuracy: 0.7712 - val_loss: 2.2526 - val_accuracy: 0.4229 - val_top-5-accuracy: 0.7249\n",
      "Epoch 170/200\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 2.0436 - accuracy: 0.4533 - top-5-accuracy: 0.7692 - val_loss: 2.1637 - val_accuracy: 0.4487 - val_top-5-accuracy: 0.7397\n",
      "Epoch 171/200\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 2.0348 - accuracy: 0.4522 - top-5-accuracy: 0.7717 - val_loss: 2.2124 - val_accuracy: 0.4346 - val_top-5-accuracy: 0.7329\n",
      "Epoch 172/200\n",
      "200/200 [==============================] - 11s 53ms/step - loss: 2.0313 - accuracy: 0.4566 - top-5-accuracy: 0.7702 - val_loss: 2.2735 - val_accuracy: 0.4216 - val_top-5-accuracy: 0.7196\n",
      "Epoch 173/200\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 2.0290 - accuracy: 0.4527 - top-5-accuracy: 0.7727 - val_loss: 2.1473 - val_accuracy: 0.4463 - val_top-5-accuracy: 0.7425\n",
      "Epoch 174/200\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 2.0149 - accuracy: 0.4599 - top-5-accuracy: 0.7752 - val_loss: 2.2002 - val_accuracy: 0.4393 - val_top-5-accuracy: 0.7360\n",
      "Epoch 175/200\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 2.0139 - accuracy: 0.4581 - top-5-accuracy: 0.7765 - val_loss: 2.1474 - val_accuracy: 0.4475 - val_top-5-accuracy: 0.7426\n",
      "Epoch 176/200\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 2.0103 - accuracy: 0.4604 - top-5-accuracy: 0.7759 - val_loss: 2.2716 - val_accuracy: 0.4223 - val_top-5-accuracy: 0.7274\n",
      "Epoch 177/200\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 2.0146 - accuracy: 0.4599 - top-5-accuracy: 0.7753 - val_loss: 2.1487 - val_accuracy: 0.4499 - val_top-5-accuracy: 0.7438\n",
      "Epoch 178/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 2.0097 - accuracy: 0.4604 - top-5-accuracy: 0.7735 - val_loss: 2.2373 - val_accuracy: 0.4264 - val_top-5-accuracy: 0.7258\n",
      "Epoch 179/200\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 2.0030 - accuracy: 0.4616 - top-5-accuracy: 0.7771 - val_loss: 2.1393 - val_accuracy: 0.4512 - val_top-5-accuracy: 0.7461\n",
      "Epoch 180/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 1.9928 - accuracy: 0.4638 - top-5-accuracy: 0.7773 - val_loss: 2.0779 - val_accuracy: 0.4625 - val_top-5-accuracy: 0.7545\n",
      "Epoch 181/200\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 1.9948 - accuracy: 0.4640 - top-5-accuracy: 0.7776 - val_loss: 2.1236 - val_accuracy: 0.4538 - val_top-5-accuracy: 0.7483\n",
      "Epoch 182/200\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 1.9912 - accuracy: 0.4652 - top-5-accuracy: 0.7775 - val_loss: 2.1219 - val_accuracy: 0.4548 - val_top-5-accuracy: 0.7453\n",
      "Epoch 183/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 1.9818 - accuracy: 0.4652 - top-5-accuracy: 0.7817 - val_loss: 2.1648 - val_accuracy: 0.4457 - val_top-5-accuracy: 0.7384\n",
      "Epoch 184/200\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 1.9840 - accuracy: 0.4638 - top-5-accuracy: 0.7787 - val_loss: 2.1132 - val_accuracy: 0.4556 - val_top-5-accuracy: 0.7465\n",
      "Epoch 185/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 1.9819 - accuracy: 0.4659 - top-5-accuracy: 0.7803 - val_loss: 2.1304 - val_accuracy: 0.4541 - val_top-5-accuracy: 0.7449\n",
      "Epoch 186/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 1.9797 - accuracy: 0.4655 - top-5-accuracy: 0.7811 - val_loss: 2.1363 - val_accuracy: 0.4509 - val_top-5-accuracy: 0.7438\n",
      "Epoch 187/200\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 1.9774 - accuracy: 0.4684 - top-5-accuracy: 0.7805 - val_loss: 2.1092 - val_accuracy: 0.4589 - val_top-5-accuracy: 0.7503\n",
      "Epoch 188/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 1.9764 - accuracy: 0.4683 - top-5-accuracy: 0.7817 - val_loss: 2.1599 - val_accuracy: 0.4486 - val_top-5-accuracy: 0.7422\n",
      "Epoch 189/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 1.9682 - accuracy: 0.4690 - top-5-accuracy: 0.7821 - val_loss: 2.1281 - val_accuracy: 0.4573 - val_top-5-accuracy: 0.7457\n",
      "Epoch 190/200\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 1.9698 - accuracy: 0.4698 - top-5-accuracy: 0.7843 - val_loss: 2.1131 - val_accuracy: 0.4578 - val_top-5-accuracy: 0.7486\n",
      "Epoch 191/200\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 1.9721 - accuracy: 0.4689 - top-5-accuracy: 0.7851 - val_loss: 2.1074 - val_accuracy: 0.4591 - val_top-5-accuracy: 0.7504\n",
      "Epoch 192/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 1.9688 - accuracy: 0.4696 - top-5-accuracy: 0.7838 - val_loss: 2.1106 - val_accuracy: 0.4578 - val_top-5-accuracy: 0.7496\n",
      "Epoch 193/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 1.9667 - accuracy: 0.4694 - top-5-accuracy: 0.7819 - val_loss: 2.0998 - val_accuracy: 0.4587 - val_top-5-accuracy: 0.7502\n",
      "Epoch 194/200\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 1.9570 - accuracy: 0.4729 - top-5-accuracy: 0.7867 - val_loss: 2.1042 - val_accuracy: 0.4590 - val_top-5-accuracy: 0.7490\n",
      "Epoch 195/200\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 1.9643 - accuracy: 0.4716 - top-5-accuracy: 0.7832 - val_loss: 2.1163 - val_accuracy: 0.4563 - val_top-5-accuracy: 0.7469\n",
      "Epoch 196/200\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 1.9544 - accuracy: 0.4711 - top-5-accuracy: 0.7836 - val_loss: 2.1144 - val_accuracy: 0.4580 - val_top-5-accuracy: 0.7490\n",
      "Epoch 197/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 1.9598 - accuracy: 0.4709 - top-5-accuracy: 0.7857 - val_loss: 2.1054 - val_accuracy: 0.4596 - val_top-5-accuracy: 0.7495\n",
      "Epoch 198/200\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 1.9576 - accuracy: 0.4737 - top-5-accuracy: 0.7866 - val_loss: 2.1077 - val_accuracy: 0.4579 - val_top-5-accuracy: 0.7489\n",
      "Epoch 199/200\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 1.9562 - accuracy: 0.4739 - top-5-accuracy: 0.7858 - val_loss: 2.1158 - val_accuracy: 0.4574 - val_top-5-accuracy: 0.7468\n",
      "Epoch 200/200\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 1.9558 - accuracy: 0.4753 - top-5-accuracy: 0.7851 - val_loss: 2.1251 - val_accuracy: 0.4554 - val_top-5-accuracy: 0.7456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2552142ee88>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(inputs = input_net, outputs = output_net)\n",
    "\n",
    "initial_learning_rate =  0.01\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
    "    initial_learning_rate,\n",
    "    alpha = 0.000001,\n",
    "    m_mul=1.0,\n",
    "    first_decay_steps = 20)\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr_schedule)\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "        ],\n",
    ")\n",
    "\n",
    "\n",
    "checkpoint_filepath = \"/tmp/checkpoint\"\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_filepath,\n",
    "    monitor=\"val_accuracy\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    ")\n",
    "\n",
    "batch_size = 250\n",
    "epochs = 200\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test), callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 490ms/step\n",
      "[59] 59\n",
      "(1, 32, 32, 16)\n",
      "[[-1.0555872  -1.0600044  -1.0584435  ... -1.0556914  -1.0551684\n",
      "  -1.0366008 ]\n",
      " [-1.0701905  -1.0555416  -1.0499995  ... -1.050111   -1.050959\n",
      "  -1.0412382 ]\n",
      " [-1.0687417  -1.0555279  -1.0523694  ... -1.0458878  -1.0475477\n",
      "  -1.0391608 ]\n",
      " ...\n",
      " [-0.88622683 -0.88193285 -0.8825614  ... -0.88899916 -0.89078826\n",
      "  -0.8950862 ]\n",
      " [-0.88863844 -0.883193   -0.8839291  ... -0.91899437 -0.92582685\n",
      "  -0.92752075]\n",
      " [-0.8975326  -0.89199173 -0.8912822  ... -0.9214062  -0.93508977\n",
      "  -0.9390587 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x256f2ffdc48>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADEAAAD8CAYAAADe6kx2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZ2UlEQVR4nO2de2xc153fP+feO3feL5IzQ3I4pESRtGSZFiXRsjdWAiWyLFcK4GyyqN0m2wCNmxRFHtvWyLrboBCySYMm264XaLGAtw2SPoKgwC6whpDFZpEUTvNHEnmV9b5k15K1ih+U+BaH5Lzn9I97z/ElJZF3SGo0zvIHXMzr3nPPb84953zP7/f9/Y6QUvJeF+NeV2AnZFeJTpFdJTpFdpUQQjwhhHhNCHFZCPHcTlWqZZFSbukATOAKMAzYwCvA/VstbzvHdlriGHBZSvmGlLIKfBd4cpv/6ZbE2sa1eeBNz+e3gIc3ukAIIS3LuaVh3P7/U/9uo9Gg2WwKPxXZjhK+RAjxaeDT7nuy2Sy2bRMMBonFYiQSCZaWlqjX69RqNarVKvV6nXfeecf3PbajxNtAwfN5wP1ujUgpXwBeAAgEAjIQCGDbNoFAgGw2y3333ce1a9eYn5+nVquxurpKuVxGCF+NAGxvdLoAjAoh9gohbOBp4EU/FzYaDSzLIplMkkwmGR4eBqBcLgOogcO3bLklpJR1IcRngT/FGam+KaX8G5/Xkk6nSaVSlMtlIpEI6XSaqakphBA0Go2W6rKtPiGl/B7wPb/nCyEQQmBZFqqDN5tNAAYGBrh8+bJujVZk08dJCFEQQvwfIcTfCiH+RgjxBff7c0KIt4UQf+EeZzYryzRNUqkU6XSa/v5+crkciUQCKSWhUIhMJkMkEiGVSmkl/YifM+vAv5ZSXhRCxIE/F0L8mfvb70opf8fvzTKZDJ/61KcwDINEIoFhGAghME2TarXKyMgI5XKZYrG4s6OTlHIKmHLfF4UQl3DmiJYllUrx1FNPYRgGq6urVCoVVldX6erqIhQKYZomjUaDqakpvv3tb++cEl4RQuwBDgM/BR4FPiuE+CfAyzittXCba/Q80dfXx+rqKqFQiFAohG3bdHd3EwgECAaDSCkRQhCJRIhGo77r5XuIFULEgD8EfkNKuQT8PrAPmMBpqf94u+uklC9IKSellJPpdJp6vU61WsUwDAKBgJ65K5UKpVKJYrHI3NxcSyOUr5YQQgRcBf6XlPKP3MrdEEI8AfweEARCfsqqVCrU63VWVlYAp7MHAgEsy6LZbLK6usrs7CylUsm3EmKziUU4U+e3gXkp5W94vs8DPwJOAR8F/i3wqJTybzcoqwi8tkmdeoBZYEhKmfGhgy8ljgP/F/groOl+/VvA54DjwFXg74C/BopSyq9tUNbLUsrJTe636Tnrxc/o9GPgFiAjhIgAb0spn3E//zq3QbHejm2a5tFsNqv/Ne8fqLBSJpMhm83KxcVFqtVqZ6BYLwDM5XLyG9/4BuBUenV1lf7+ft5++21isZj3Gp599lnf97jrKHa9qNGo2WySSCQYGxtDSsns7CzhcBgppYYifuWeoFhwEKtt28zNzdHT00OlUmkZ+CnZshJSyjqgUOwl4H/7QbGqJcLhMJlMRq8dent7qVQqa87xK9uydkgpvyelHJNS7pNSfnWjc905RV2HEIJyuUy1WqVcLpPJZKjVavpRchGvL2DZFhQrhDCB/2IYBo1Gg1qtRjweJxwOI4TQj5JlWdRqNer1OkIIpJQTLtzfUNqFYo8Bl8Ph8HB/fz+NRoNIJIKUUmMky7IoFAoEAgGklITDYR/FOrJpS0gpp6SUF933RZznv1UUmwfetCyLYDBIKBTSGKrRaLCyssLKygq2baPOCQQCCCG+KYRIb1sJr6xDseCg2L/c6GbuZPcfgCdv3rypn3mFmYQQhMNhjZ+klNTrdTUR3hFYbkmJ7aBY4BPAxVQqpeeBRqOh33sP1eld+QOcR3FDaReKvQCMArqiStZPbGod7sqv4mCyjcWHzVUA/x14ft33ed61xT4LLLCBLRY4gwMgyzjWwlcBCax6jteBZfd9HWfy7Nusjr8UKHZTJTa42a8BT6xHsVLKz647T6PYQCBwtFB4F241Gg0CgQDVahXTNNdY/aamplhdXe08FNvX1ye/9jWnodQSdXx8nMuXL7OwsEAkEtGKfOELX/B9j+3Aji2hWCWVSgXLspienqarq4tyudyy+VJJ21GsCye0paNUKtFsNslms1QqlfWjky9pO4pVvgeAUqmkjQbd3d1Uq1XdGu2yireMYr0AMBKJYNs24PSPWq2GYRhUKhWq1WpLKHbTji2EKODMEzmccf0FKeXvCSHOAf8MmHFP/a07IU6FYi3LwrZtDMMgHA5TrVa1IgCJRELjJ9u2kVJObFY/X0qwgyjWsqzhYDBIMBikVqtRq9UIBAKUy2VM08S2bUzTBNCvfqStKBbQGEkIgW3bGgAqBRQABDoTxRaLRQ0VFIbyvnoVdKUtKPZf4IC/jwDfv911XhSbSCTWoNVGo7HmqNfrNJtN3RL4RLF+He8BnKH0X3m+8zrjR4ESdwCAOH3vDWAF+HMcgPfXOObKGzhWdXW86b7OAP8S+O5m9fOzxhbAfwMuSSn/k+enf4DrjAc+DPw/7uCM98wpJpACvgr8c6DbVcJyj38HRHBadwr4oKvIxuKjFY7jDK1/CfyFe5wBXgLm3e9fdCv5nzcp62Uf99v0nPXHdm2x61HsLbLOGX80EAhIr1kmFouxsrKiZ3HDMLAsS7p9xte0fdcBoPQ4WWzbJp1OE41GCYVCfOhDH+L8+fN87nOfIxQKaf+dcn35lbYDQNM0MU2TSCTCgw8+SDab5ezZsxQKhZaBn5K2AkAhhDbZ3HfffRw75oyee/fu5fTp00QiEUKhEMFgsDMBIKAxUywWo1AokEgkaDQa2LbNyZMnyefzRKNRotFoS/bYtjnjhRBPBINB9uzZw969ezl69Cijo6PE43EA8vk8hw8fZnBwkJGREdVHdgbFsgMAUKHYRCLB2bNnkVJy6NAhAoEAoVBI+ypOnz7N0tIS8Xica9eusbCwMOGjfm1zxh8DLsdiseETJ07oR0it5FZWVqjX64yPj+t+E4lEfBd+153xruSBNwOBAMqg7JYHQDAYXGMRlFIqysQ3NykXaIMZ04ti5+bm9OhjWZY20yjHvG3bhEIhIpGI6ti+UOxdN2NKKV8QQvwVcC6TyTxuWRaGYWjIoFpFra3VqOS+/gFwftMK+sAy2zZjcpdR7HYA4J8ARd4FgP8e+DcblHMGxw57BYd9cKdy53BMpqrc7dti7yRbMWMKIY4Gg0Ff5bsOmM4zY4bDYblv3z49+iQSCXK5HMVikenpae/amitXrvi+R9vNmN6WTyaT1Ot1YrHYGpjR6tNxT5zxwiVm1Wo1FhYWKBaL2t60FWk7pVTZWtX8EIvFWF5e1nzArcDxtlJK9U0tSy98isWi5sZuhU4KbUax3s/BYJD5+XnAWSg1m039SFmWtbO2WHYQxbrvMQxD0yGklNqArNbejUZDMwp81K+9KFYIMayG0fn5ee3uqtfrFItFTNP0UiJ8F94uM+b/BI7UajWANWyC5eVl7deuVqtrfNw7bovdKop1J7vfBP74TkPoel+2Z87oDBTryvqJ0a/sothdFLvuPI1ibds+OjAwoH9rNptYlkW9Xr/FRHP9+nVWVlY6D8Xm83n59a9/HUBXfP/+/Vy7do3FxUVCoXe71ec//3nf97hnzvhqtYplWczPz5NKpahUKmvmhnZZALfljA8EAnR1denKZzKZ95Yz3p3IKJfLNBoNyuUy6XRaT3KtStud8c1m8xZnvApHME2TWq2msZNfANhWSqllWYTDYaLRKOFwmHq9TiAQ0NTSRCJBKpUimUyqyJYJ2WmUUsuyhkOhEFI6vmqlRKVSwTAMzTZQSNev3BNnvDIUqMdJxRcpo5rHzNl5zvilpSXdsZUyt/vsGZ06j1K63hmv3rthy2teXfHljPcFO1wUex74U+nxZa9HsVLK3jtcb+H4uXM4LMwDOICwF2iwNq47hwMKh3Dw2MNSyqc3rGA7UOw9B4DiPUApbWtglGEYR23blp7lJ9FolNXVVb26U854t7/cdWe8L5EeZ7xpmsTjcT2kHj58mB/+8Id84hOfWBNMq3hQfqXtKFZV1rIsxsfHCQaDPP7446RSqZbDcHSZW7rKkZZRrHBZZoZh0Nvby8mTJ4lGoxw5coQPfOADawxnrUhbUaxhGCSTSaLRKKOjo/T19emolrNnz5JMJlWf2FnYsYkiLaHYYDBIKpWiq6uL8fFxcrmcnvCGhobYs2cPPT09DA8PK2pE51FKq9UqU1NTNBoNfvGLX3D+/Hm9MLpx4wYrKyuEw2EGBgZ46623WF5entisfuAvgLYPZ8LRKBaH8/cPgWU/KFYI8SvAOcuyHleBT6FQiFgsxsDAAK+//jrlcll7ivr6+lheXmZmZmZnhtidRLHRaJR9+/bR1dWlLeFXr17V9GrTNDEMg5mZGRYXFzsTxdbrdXp7e8lms3oh1Gg09NzgZeC4DkpfKNa33clFsS8BX5VS/pEQIgccBX4XyABXpJQP3eHaXwHO9fT0PH7q1ClKpZLGPcViUSdcsCyLTCbD2NgYL774IlevXt0LnJdSPrBh5TYDV66Su5RSeZcppdtBsb8JjONEav0dDkN5/3ozplcsy5LK7nS7+6qZWnmNdswZvwmKbYlSalkW6XRaB8zats373vc+Ll68yMLCAoZh6EjIpaUlP/UH2kwpVYYAJZOTkzz33HM8/fTTOgK4Wq2uiWi520psyYypeE7hcJgHHniA7u5uzpw5Qz6fXwP82gLFtwIAhUuNCwaDjI2NcezYMaSU7Nmzh1OnTunfOppSqqB4LBYjn88Ti8Wo1+tYlqUppZFIxMs82xkldtIZHwwGGRoaYmhoiMnJScbGxkgmkwD09/czMTHBwMAAw8PDnUspTaVSfOQjH6HZbDI+Pq75fs1mk3Q6zZkzZygWi0SjUb785S+zuLg44aN+7XXGx+Px4ZMnT2o3lwpXW11dRUrJ0aNHnUpZVmdTStVCyC1P95P1MUYuU7MzKaXBYFATUbyUUsuyNK00GAx2NqVUVVxNZuuzpoi1vI5dZ7y3Ah3vjPe1nrhDpX4N+K+ez7/ObQKjcMDfy8DLQghpmqY0DEMfpmnq74QQ+jvDMKTfurSdUhoKhSiXy8RiMXp6ejh8+DCvv/46MzMzlEol7VGtVqu+79F2M2Y4HCaZTJJKpTh48CAf/ehHOXv2LD09PSQSCXp6em6hmG4m22kJjWLdyj8N/OONLjBNk+7ubufGlsXIyAjd3d3s37+fn//85zp007ZtisWi74q0lVJqGAa5XI5SqUQ6nWbfvn1EIhEGBweZmJhgbm6OlZWVlkPU2kopVdRq27YpFAqkUilqtRrhcJiDBw9y6dIlbt68iWmaXL582Xc92o5ic7kcAwMDjI2N0dvbSzgcJhgM6sdqz5492szfkSg2Fovx6KOP0mw2iUQilEolGo0G09PTVKtVDhw4QKFQoFKp8JOf/IS5ubkJH/VrL4pdWloa/ta3vkWlUmHv3r309vYSiUR47bXXmJmZ0WH+x44dw2+IArSZUlqv1xkZGaG/v59arcb09DQ/+9nPeOutt5iZmWF5eZnZ2Vl+9KMfMT093ZmU0ng8TjKZJJFIUKlUmJubo1wu02w2icfjdHV1MTg4yP33368oE52BYl15GygIIeju7iYajTIwMEClUtG22Gq1qlMQj4+Pc+HCBa5fv76LYt9TKLatlFLDMI7G43HvogfbtqnVaqyvhxvK2XmU0lgsJo8fPw6g4yWeeOIJLl68uCZ7dbPZ5KWXXvJ9j7ajWGXZk9JJj3Tt2jV6enqAW4nvfuWeUErBeYwSiQQzM47ztaenBykda4diHfiVtlNKlZlGMTOFEBSLRUZGRrQFpKOzlHodLOFwmO7ubkzTpFQq8c4776wJUROdmt8pEolw4sQJhBDcvHmT6elpDMPQrJuHH34Yy7JYXFzkpz/9KcVicWKz+vlSgh2klDYajeFLly6tYWI2m801SdGFy8DZ0T4hd5hSquyvpVJJe4a8vjoppTdnbOc541V6YSml3oNlfU4nIQSBQEBd3nmU0lAopEce73zhfVW/eSLjdymlO4Zi7zkA3MAZ//eTUgocVTZW9zftMfLiJiGEdFkFnYdiLcuSCm4A5HI5Dh06xJtvvsmrr76q405bmSPgHlJKA4EA6XSaQqHA/v37icViLVdel7mlqxzZEqXUNE0syyKRSNDd3U2j0SCfz9Pf369ZmOsT4N41JbaKYpVvLhKJEAwGtYGgUCgQi8UIBAI6VfeOKbGRGRNnMlrFWWv/fJNynlA0a2XCHxkZYf/+/USjUSKRCN3d3fr3jjVjBgIBhoaGAKdTZ7NZBgcHqVQqTE1NMT8/T09PD5Zl8corr1CpVCZ81K/9zvhDhw5RrVaJRCLagHbt2jVqtRqDg4NI6eTff+ONN3wX3lZnfDKZ5Mknn9QMAtWR+/r6KJVKOm8BwPe//33fznjfSqwHgEKI3wd+Gwc6/DYOAPynt7nu0zhmzESxWKRQKLC8vKz3KVLpLrzBsyrpLe8Cy1vKbVmJnXTGJxIJwuEwXV1d1Go1VlZW8M7ganRyldg1Y+6aMe90TSAQkN5UYesXQupVuPTrjjFjirW59snlcnpDGdM0ef/738+FCxdYWFjQHToYDDI7O+v7Hm2nlHojGx966CG+9KUv8fGPfxyA1dVVVlZW9BDcDiW2ZMY0DEPnyHzwwQdJp9N8+MMf1pRSKdu4Y9RWAKBw03CHQiHGxsZ45JFHkNKhlJ49e5ZIJEI4HNa5Y++6Eq4i28pSGo/H9f5Ejz32GIVC4b1BKd2zZ4+mlI6OjqIigwcGBpiYmKBQKHR2ltJ4PM5jjz1Go9HgyJEjOp2kYl9+8IMfZHJyknQ6zRtvvNGZWUrj8fjw6dOnNStZhfWrRNCTk5PaeNDKjlFtp5T29vau2Y/IMAxN8PUGnHcspXR+fl6b8b3LULXuVhOdCu3cqFyv3BNKqRd6eOcE5eryGJh3Uewuil13njem6Khy925SNnNzc1Qqlc5AsXJdfqfnn39e/1YsFslms0xPT2sLoIIbreR32o4SLZsx1bAqpdRx2ENDQ0gpWVhYWLPO7mgUq6RcLmNZFnNzczpsbauPdttRrHut3jGqUqnoHaMUK7lVy/g9yVKq/nFFqRZC0NXVpRN+ttoibUWxau2sklQpsqLaMco0TZ2wSnRqllKFVuv1us7cqxQRbpIqlTFCJanyUb/2oli1Y5Rt27ckqVKB5XclSZVXxDYppUtLS7ckqRJCEAqF9P7xavh1r+08SmkymVwD/O4II94dnToDxbqiJ8b1gVCq0uvFHaF2Uewuil133potQ/N5Z2BTHdi27dtuGXr9+nVKpVLnodhcLifPnTuHlFJvh/jwww/z6quvMjU1pbcMFULwxS9+0fc92u6MV1IqlbBtmxs3buhdytsOANlmltJQKEQul9PoNZ/P6w1dW6WUtj3XvpojhJulVBkKstksN27c2FJrtJVSqmbker2u94yHd7OUWpal843vqDNe7CClVGUktSyLaDRKpVJZE3aTSqW0TcpNBDqxWf18KcEOUkoDgcBwNBrVw2utVsO2bUqlkt4CTtFJOzZLqerUCgCq4HG1v51iYXqS3nYepfR2WUo32TO+87cMVf672x2u7G4Z6m2Bjs/vtB0U+/d3y1AvpVSNTGqzbyWGYUigLVlKW3bGe7ePtiyL48eP853vfIfPfOYzOhpeodh2pZXcEhtTmWQikQgHDx6kt7eX06dP09/fr89pBfzBPTBjqk35RkdHde6awcFBTpw4oVup1fxObY+Mj0QiNBoN+vv7tTNehen84Ac/YHZ2Vu+Y47vczU7YaWf80NAQw8PDOr+TioLv7+/n8OHDFAqFzs7v1NXVxSc/+UmklBw4cIB0Oq3QKkIIPvaxj7G4uIht23zlK1/h5s2bEz7q1/4tQ0+dOqXzOylPaqVSIRwO89BDTlZKwzDwepS2rYRXtuuMV7kvvZmrhZvfCd5d9UnZwc74ubk5bNvWCx9lplE7NSseuSdEbedQ7J3MmMApnOH14zhQ5BbxothMJqMNAd7wTDW5qe89SuwMimXXjPlLYsb0imVZt9xMLVnXi5T+94xvK6XUNE2SyaQeYmOxGOPj41y5ckXvb6dGp47NUuqlBNm2zcGDB3nmmWd48sknSaVSazY7bkXabsZUlQyFQoyOjpLL5XjkkUfo7e3VM3dHxxQpM41t2wwNDXH//fcDUCgUmJyc1ENuqzFFbUWxQghNlctms8TjcZ3f6dixY/z4xz9mdnZ253Pt7zSKzefzFAoFHnjgAfbt20cqlUIIQSaT4cCBA/T395PP55VntfNQbE9PD8888wzgPELZbJZgMEiz2SQUCvHUU0+xuLhIo9Hg6tWrnYliw+Hw8JEjR3TiEWW2bDabBINBRkZGnEq5w69fuesoVnhiihYXF0mn03oUUhOd2kRAKQQa4XYGipUeZ3wmk9HoVXVcpZACgArJunL3nfGe3zdzmuuJ0TvqeA3IakhV7z0odlNnvB8ny23NmEKIPre/APwqDiq9k1wARi9evLgaDodbCe/frFxHtoFi/wctoE06EcVuRcRdCu/fluOxU6TdSrywQ+eskbY+TndLdh+nVkQ4bMzXhBCXhRDP7RSwBLaeQ7mVg7X+PRt4BfgAcMT9PY7jLrsfOAc820r57WqJY7j+PSllFfgu8Kjcvn8caN/jpPM7ufIWngpvxT/ulXvesbcKLL3SLiVuaxm5E7CUUjaklE18mjHbpcSdLCO3BZae63wBwLZNdu5Q+TwuwQvHD367lEv/COdRkjgplz7jQcu3L3t3xu4Q2VWiU2RXiU6RXSU6RX4plPj/QVzxXBdRYRMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_layer_output = K.function([model.input], model.layers[1].output)\n",
    "\n",
    "n = 109\n",
    "\n",
    "X = np.expand_dims(x_test[n], axis=0)\n",
    "print(y_test[n], np.argmax(model.predict(X)))\n",
    "\n",
    "\n",
    "layer_out = np.array(get_layer_output([X]))\n",
    "print(layer_out.shape)\n",
    "\n",
    "print(layer_out[0, :,:, 0])\n",
    "fig, ax = plt.subplots(16)\n",
    "for i in range(16):\n",
    "    ax[i].imshow(layer_out[0, :,:, i],  cmap='gray')   \n",
    "\n",
    "plt.figure(2)  \n",
    "plt.imshow(x_test[n],  cmap='gray')   \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18412\\3066593953.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "model.layers[4].trainable_variables[3].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'sorted_conv2d/scale_sym:0' shape=() dtype=float32, numpy=-0.0684901>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].scale_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[ 1.057311  , -0.15671223,  1.057311  ],\n",
       "       [-0.15671223, -0.23184319, -0.15671223],\n",
       "       [ 1.057311  , -0.15671223,  1.057311  ]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].get_sym_filter(0,3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('masters')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f2ff97d05f7ea74f9ad893ce0ef62de10b7e20c3f21fc0f5866920ae6ae88e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
